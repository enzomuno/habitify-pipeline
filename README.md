# üìä Habitify Data Pipeline

Este reposit√≥rio cont√©m a pipeline de dados desenvolvida para ingest√£o, transforma√ß√£o e modelagem dos dados extra√≠dos da API do Habitify. A arquitetura utiliza armazenamento em S3, processamento no Snowflake e transforma√ß√µes com dbt Cloud.

## üîß Arquitetura

1. **Coleta (EL)**  
   Os dados s√£o coletados da API do Habitify com um script Python, armazenados em arquivos `.json` no Amazon S3 organizados por data (`YYYYMMDD`).

2. **Ingest√£o para Snowflake (L)**  
   Uma procedure no Snowflake (`ingest_habitify_data`) √© executada diariamente via `TASK`, realizando:
   - **Sobrescrita** das tabelas `areas` e `habits`
   - **Acrescenta dados** nas tabelas `journal`, `moods` e `notes`

3. **Transforma√ß√£o (T)**  
   O dbt Cloud transforma os dados brutos em modelos organizados por camadas:
   - `stg_*`: staging com limpeza e tipagem
   - `core_*`: estrutura√ß√£o de entidades principais
   - `mart_*`: modelos prontos para an√°lise

## ‚è±Ô∏è Agendamentos

- **GitHub Actions (Python EL)**: roda diariamente √†s **22:30 BRT** (`01:30 UTC`)
- **Snowflake TASK**: ingest√£o di√°ria agendada √†s **01:30 UTC**
- **dbt Cloud Job**: execu√ß√£o di√°ria do pipeline √†s **02:00 UTC** (23:00 BRT)

## üì¶ Tecnologias

- **Python 3.10+**
- **AWS S3**
- **Snowflake**
- **dbt Cloud**
- **GitHub Actions**
